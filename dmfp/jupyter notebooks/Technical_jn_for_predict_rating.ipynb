{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code of Amazon Product Rating Prediction System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAY ATTENTION:\n",
    "\n",
    "Because all the functions are defined under the AmazonRatingPredictor class, but jupyter notebook will break this relationship, so we cannot run the code completely here. I submitted the complete code in the source code file, and it can run normally. This document merely explains the technical logic of my code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries and file comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definition and initialization of predictor classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonRatingPredictor:\n",
    "    \"\"\"Amazon Product Rating Predictor Class\"\"\"\n",
    "    \n",
    "    def __init__(self, model_dir='model_results', use_latest=True):\n",
    "        \"\"\"\n",
    "        Initialize the predictor\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Model files directory\n",
    "            use_latest: Whether to use the latest model files\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.tfidf = None\n",
    "        self.label_encoder = None\n",
    "        self.feature_names = None\n",
    "        self.model_info = None\n",
    "        self.model_type = None\n",
    "        self.model_dir = model_dir\n",
    "        self.load_model_components(use_latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AmazonRatingPredictor class for rating prediction\n",
    "\n",
    "The initialization method sets two parameters:\n",
    "\n",
    "    model_dir: Directory of model files, with the default being 'model_results'\n",
    "    use_latest: Whether to use the latest model file. The default is True\n",
    "\n",
    "Initialize instance variables:\n",
    "\n",
    "    model components: model, scaler, tfidf, label_encoder\n",
    "    Metadata: feature_names, model_info, model_type\n",
    "    Configuration: model_dir\n",
    "\n",
    "Call the load_model_components method to load the model components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model file search and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_model_files(self):\n",
    "        \"\"\"Find the model files\"\"\"\n",
    "        # Use fixed filenames\n",
    "        return {\n",
    "            'model': os.path.join(self.model_dir, 'best_model.pkl'),\n",
    "            'scaler': os.path.join(self.model_dir, 'scaler.pkl'),\n",
    "            'tfidf': os.path.join(self.model_dir, 'tfidf.pkl'),\n",
    "            'label_encoder': os.path.join(self.model_dir, 'label_encoder.pkl'),\n",
    "            'model_info': os.path.join(self.model_dir, 'model_info.pkl')\n",
    "        }\n",
    "    \n",
    "def load_model_components(self, use_latest):\n",
    "    \"\"\"Load model components\"\"\"\n",
    "    try:\n",
    "        if use_latest:\n",
    "            files = self.find_latest_model_files()\n",
    "            print(f\"Using latest model files...\")\n",
    "        else:\n",
    "            # Use fixed filenames\n",
    "            files = {\n",
    "                'model': 'amazon_rating_prediction_model.pkl',\n",
    "                'scaler': 'amazon_rating_scaler.pkl',\n",
    "                'tfidf': 'amazon_rating_tfidf.pkl',\n",
    "                'label_encoder': 'amazon_rating_label_encoder.pkl',\n",
    "                'model_info': None\n",
    "            }\n",
    "            \n",
    "        # Load model components\n",
    "        self.model = joblib.load(files['model'])\n",
    "        self.scaler = joblib.load(files['scaler'])\n",
    "        self.tfidf = joblib.load(files['tfidf'])\n",
    "        self.label_encoder = joblib.load(files['label_encoder'])\n",
    "            \n",
    "        # Load model info (if exists)\n",
    "        if files['model_info'] and os.path.exists(files['model_info']):\n",
    "            self.model_info = joblib.load(files['model_info'])\n",
    "            self.model_type = self.model_info.get('best_model_name', 'Unknown')\n",
    "            self.feature_names = self.model_info.get('feature_names', [])\n",
    "            print(f\"Model type: {self.model_type}\")\n",
    "        else:\n",
    "            # Try to infer from model object\n",
    "            model_class_name = type(self.model).__name__\n",
    "            self.model_type = model_class_name\n",
    "            print(f\"Inferred model type: {self.model_type}\")\n",
    "            \n",
    "        print(\"Model components loaded successfully!\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Model file not found: {e}\")\n",
    "        print(\"Please make sure you've run the training script and generated model files\")\n",
    "        print(f\"Search directory: {self.model_dir}\")\n",
    "            \n",
    "        # List available model files\n",
    "        if os.path.exists(self.model_dir):\n",
    "            pkl_files = glob.glob(os.path.join(self.model_dir, '*.pkl'))\n",
    "            if pkl_files:\n",
    "                print(\"\\nAvailable model files:\")\n",
    "                for f in pkl_files:\n",
    "                    print(f\"  - {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The find_latest_model_files method:\n",
    "\n",
    "    Return the path dictionary of the latest model file\n",
    "    Use fixed file name formats: best_model.pkl, scaler.pkl, etc\n",
    "\n",
    "The load_model_components method:\n",
    "\n",
    "    Select to use the latest model file or the fixed name file based on the parameter use_latest\n",
    "    Load the model components using joblib: the model, the normalizer, the TF-IDF vectorizer, and the label encoder\n",
    "    Load model information (if present) : model type and feature name\n",
    "    If the model information does not exist, try to infer the model type from the model object\n",
    "    Exception handling: Capture the file not found exception and provide useful error information\n",
    "    List the available model files to help users troubleshoot problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data cleaning and processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(self, price_str):\n",
    "    \"\"\"Clean price data\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return 0\n",
    "    price_clean = re.sub(r'[₹,]', '', str(price_str))\n",
    "    try:\n",
    "        return float(price_clean)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def clean_discount(self, discount_str):\n",
    "    \"\"\"Clean discount percentage data\"\"\"\n",
    "    if pd.isna(discount_str):\n",
    "        return 0\n",
    "    discount_clean = re.sub(r'%', '', str(discount_str))\n",
    "    try:\n",
    "        return float(discount_clean)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def clean_rating_count(self, count_str):\n",
    "    \"\"\"Clean rating count data\"\"\"\n",
    "    if pd.isna(count_str):\n",
    "        return 0\n",
    "    count_clean = re.sub(r'[,]', '', str(count_str))\n",
    "    try:\n",
    "        return int(count_clean)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def extract_features(self, product_data):\n",
    "    \"\"\"\n",
    "    Extract features from product data\n",
    "    \n",
    "    Args:\n",
    "        product_data: Dictionary containing product information\n",
    "        \n",
    "    Returns:\n",
    "        Processed feature vector\n",
    "    \"\"\"\n",
    "    # Clean price data\n",
    "    discounted_price = self.clean_price(product_data.get('discounted_price', '0'))\n",
    "    actual_price = self.clean_price(product_data.get('actual_price', '0'))\n",
    "    discount_percentage = self.clean_discount(product_data.get('discount_percentage', '0'))\n",
    "    rating_count = self.clean_rating_count(product_data.get('rating_count', '0'))\n",
    "    \n",
    "    # Calculate derived features\n",
    "    price_ratio = discounted_price / (actual_price + 1)  # Avoid division by zero\n",
    "    absolute_savings = actual_price - discounted_price\n",
    "    \n",
    "    # Text features\n",
    "    product_name = product_data.get('product_name', '')\n",
    "    about_product = product_data.get('about_product', '')\n",
    "    category = product_data.get('category', '')\n",
    "    \n",
    "    product_name_length = len(product_name)\n",
    "    about_product_length = len(about_product)\n",
    "    category_depth = category.count('|') + 1 if category else 1\n",
    "    \n",
    "    # Main category\n",
    "    main_category = category.split('|')[0] if category else 'Unknown'\n",
    "    \n",
    "    # Numeric features (maintain same order as in training)\n",
    "    numeric_features = np.array([\n",
    "        discounted_price, actual_price, discount_percentage,\n",
    "        rating_count, price_ratio, absolute_savings,\n",
    "        product_name_length, about_product_length, category_depth\n",
    "    ])\n",
    "    \n",
    "    # Category feature encoding\n",
    "    try:\n",
    "        main_category_encoded = self.label_encoder.transform([main_category])[0]\n",
    "    except:\n",
    "        # If new category, use the encoding of the most common category\n",
    "        main_category_encoded = 0\n",
    "        print(f\"Unknown category '{main_category}', using default encoding\")\n",
    "    \n",
    "    # Text features (TF-IDF)\n",
    "    text_features = self.tfidf.transform([about_product]).toarray()[0]\n",
    "    \n",
    "    # Combine all features (maintain same order as in training)\n",
    "    features = np.concatenate([\n",
    "        numeric_features,\n",
    "        [main_category_encoded],\n",
    "        text_features\n",
    "    ])\n",
    "    \n",
    "    # Choose whether to standardize based on model type\n",
    "    features = features.reshape(1, -1)\n",
    "    \n",
    "    if self.model_type in ['Linear Regression', 'LinearRegression']:\n",
    "        # Use standardization for linear regression models\n",
    "        features = self.scaler.transform(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean_price, clean_discount, clean_rating_count: Data on cleaning prices, discounts and rating counts.\n",
    "\n",
    "extract_features: Extract features from product data, including numerical features, category codes and text features (TF-IDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Prediction and Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(self, product_data):\n",
    "    \"\"\"\n",
    "    Predict product rating\n",
    "    \n",
    "    Args:\n",
    "        product_data: Product information dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Predicted rating value\n",
    "    \"\"\"\n",
    "    if self.model is None:\n",
    "        print(\"Model not loaded, cannot make predictions\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Extract features\n",
    "        features = self.extract_features(product_data)\n",
    "        \n",
    "        # Predict rating\n",
    "        predicted_rating = self.model.predict(features)[0]\n",
    "        \n",
    "        # Ensure rating is within reasonable range\n",
    "        predicted_rating = max(1.0, min(5.0, predicted_rating))\n",
    "        \n",
    "        return round(predicted_rating, 2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the \"extract_features\" method to extract features.\n",
    "\n",
    "Use the loaded model to predict the score and limit the result to between 1.0 and 5.0.\n",
    "\n",
    "Capture and print the anomalies in the prediction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Analysis of Prediction results and suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(self, product_data):\n",
    "    \"\"\"\n",
    "    Predict rating and provide confidence analysis\n",
    "    \n",
    "    Args:\n",
    "        product_data: Product information dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing predicted rating and analysis\n",
    "    \"\"\"\n",
    "    predicted_rating = self.predict_rating(product_data)\n",
    "    \n",
    "    if predicted_rating is None:\n",
    "        return None\n",
    "    \n",
    "    # Analyze influencing factors\n",
    "    analysis = self.analyze_prediction_factors(product_data)\n",
    "    \n",
    "    return {\n",
    "        'predicted_rating': predicted_rating,\n",
    "        'rating_level': self.get_rating_level(predicted_rating),\n",
    "        'analysis': analysis,\n",
    "        'recommendations': self.get_recommendations(product_data, analysis),\n",
    "        'model_type': self.model_type\n",
    "    }\n",
    "\n",
    "def get_rating_level(self, rating):\n",
    "    \"\"\"Get rating level description\"\"\"\n",
    "    if rating >= 4.5:\n",
    "        return \"Excellent (4.5-5.0)\"\n",
    "    elif rating >= 4.0:\n",
    "        return \"Good (4.0-4.5)\"\n",
    "    elif rating >= 3.5:\n",
    "        return \"Average (3.5-4.0)\"\n",
    "    elif rating >= 3.0:\n",
    "        return \"Below Average (3.0-3.5)\"\n",
    "    else:\n",
    "        return \"Poor (1.0-3.0)\"\n",
    "\n",
    "def analyze_prediction_factors(self, product_data):\n",
    "    \"\"\"Analyze key factors influencing the prediction\"\"\"\n",
    "    analysis = {}\n",
    "    \n",
    "    # Price analysis\n",
    "    discounted_price = self.clean_price(product_data.get('discounted_price', '0'))\n",
    "    actual_price = self.clean_price(product_data.get('actual_price', '0'))\n",
    "    discount_percentage = self.clean_discount(product_data.get('discount_percentage', '0'))\n",
    "    \n",
    "    if discounted_price > 0:\n",
    "        analysis['price_factor'] = \"Reasonable price\" if discounted_price < 1000 else \"High-priced product\"\n",
    "    \n",
    "    if discount_percentage > 50:\n",
    "        analysis['discount_factor'] = \"High discount advantage\"\n",
    "    elif discount_percentage > 20:\n",
    "        analysis['discount_factor'] = \"Moderate discount\"\n",
    "    else:\n",
    "        analysis['discount_factor'] = \"Low discount\"\n",
    "    \n",
    "    # Description analysis\n",
    "    about_product = product_data.get('about_product', '')\n",
    "    if len(about_product) > 500:\n",
    "        analysis['description_factor'] = \"Detailed product description\"\n",
    "    elif len(about_product) > 200:\n",
    "        analysis['description_factor'] = \"Basic product description\"\n",
    "    else:\n",
    "        analysis['description_factor'] = \"Minimal product description\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def get_recommendations(self, product_data, analysis):\n",
    "    \"\"\"Provide improvement suggestions based on analysis\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Suggestions based on description length\n",
    "    about_product = product_data.get('about_product', '')\n",
    "    if len(about_product) < 200:\n",
    "        recommendations.append(\"Enrich product description content, detailing product features and benefits\")\n",
    "    \n",
    "    # Suggestions based on pricing\n",
    "    discount_percentage = self.clean_discount(product_data.get('discount_percentage', '0'))\n",
    "    if discount_percentage < 10:\n",
    "        recommendations.append(\"Consider adding an appropriate discount to increase product attractiveness\")\n",
    "    \n",
    "    # Suggestions based on category\n",
    "    category = product_data.get('category', '')\n",
    "    if not category:\n",
    "        recommendations.append(\"Ensure accurate product categorization to help users find the product\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"Product information is fairly complete, continue maintaining quality standards\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_with_confidence: Encapsulate the prediction results, including ratings, grades, analyses and suggestions.\n",
    "\n",
    "get_rating_level: Return the level description based on the score.\n",
    "\n",
    "analyze_prediction_factors: Analyze the key factors that affect the prediction (such as price, discount, description length).\n",
    "\n",
    "get_recommendations: Provide improvement suggestions based on the analysis results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Demonstration and interaction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_prediction():\n",
    "    \"\"\"Demonstrate prediction functionality\"\"\"\n",
    "    print(\"Amazon Product Rating Prediction Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create predictor instance\n",
    "    predictor = AmazonRatingPredictor()\n",
    "    \n",
    "    if predictor.model is None:\n",
    "        print(\"Model loading failed, cannot run demo\")\n",
    "        return\n",
    "    \n",
    "    # Sample product data\n",
    "    sample_products = [\n",
    "        {\n",
    "            \"product_name\": \"High-Quality Wireless Bluetooth Earphones\",\n",
    "            \"category\": \"Electronics|Audio|Headphones\",\n",
    "            \"discounted_price\": \"₹999\",\n",
    "            \"actual_price\": \"₹1,999\",\n",
    "            \"discount_percentage\": \"50%\",\n",
    "            \"rating_count\": \"1,250\",\n",
    "            \"about_product\": \"These wireless Bluetooth earphones use the latest Bluetooth 5.0 technology, providing exceptional sound quality. Features active noise cancellation, 35-hour battery life, and IPX7 waterproof rating. Suitable for sports, commuting, and everyday use. Package includes earphones, charging case, USB-C charging cable, and multiple sizes of ear tips.\"\n",
    "        },\n",
    "        {\n",
    "            \"product_name\": \"Basic Charging Cable\",\n",
    "            \"category\": \"Electronics|Cables\",\n",
    "            \"discounted_price\": \"₹99\",\n",
    "            \"actual_price\": \"₹199\",\n",
    "            \"discount_percentage\": \"50%\",\n",
    "            \"rating_count\": \"50\",\n",
    "            \"about_product\": \"Standard charging cable\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, product in enumerate(sample_products, 1):\n",
    "        print(f\"\\nProduct {i}: {product['product_name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        result = predictor.predict_with_confidence(product)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"Predicted Rating: {result['predicted_rating']}/5.0\")\n",
    "            print(f\"Rating Level: {result['rating_level']}\")\n",
    "            print(f\"Model Used: {result['model_type']}\")\n",
    "            print(f\"Key Factors: {', '.join(result['analysis'].values())}\")\n",
    "            print(\"Recommendations:\")\n",
    "            for rec in result['recommendations']:\n",
    "                print(f\"  • {rec}\")\n",
    "        else:\n",
    "            print(\"Prediction failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Model validation and Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_real_data():\n",
    "    \"\"\"Validate model accuracy using real data\"\"\"\n",
    "    print(\"Validating Model Accuracy with Real Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create predictor instance\n",
    "    predictor = AmazonRatingPredictor()\n",
    "    \n",
    "    if predictor.model is None:\n",
    "        print(\"Model not loaded, cannot validate\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load original data\n",
    "        print(\"Loading original dataset...\")\n",
    "        df = pd.read_csv('amazon.csv')\n",
    "        print(f\"Data loaded successfully, {len(df)} records\")\n",
    "        \n",
    "        # Data preprocessing (consistent with training)\n",
    "        def clean_rating(rating_str):\n",
    "            if pd.isna(rating_str):\n",
    "                return np.nan\n",
    "            try:\n",
    "                return float(str(rating_str))\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        df['rating'] = df['rating'].apply(clean_rating)\n",
    "        df = df.dropna(subset=['rating'])\n",
    "        \n",
    "        # 增加测试样本数量并使用分层抽样\n",
    "        # 允许用户选择测试样本的大小\n",
    "        print(\"\\nSelect test sample size:\")\n",
    "        print(\"1. Small (100 samples)\")\n",
    "        print(\"2. Medium (300 samples)\")\n",
    "        print(\"3. Large (500 samples)\")\n",
    "        print(\"4. Very Large (1000 samples)\")\n",
    "        print(\"5. Custom size\")\n",
    "        \n",
    "        sample_choice = input(\"Enter your choice (1-5), or press Enter for default (300): \").strip()\n",
    "        \n",
    "        if sample_choice == '1':\n",
    "            test_size = 100\n",
    "        elif sample_choice == '2' or sample_choice == '':\n",
    "            test_size = 300\n",
    "        elif sample_choice == '3':\n",
    "            test_size = 500\n",
    "        elif sample_choice == '4':\n",
    "            test_size = 1000\n",
    "        elif sample_choice == '5':\n",
    "            try:\n",
    "                custom_size = int(input(\"Enter custom test size: \").strip())\n",
    "                test_size = max(10, min(custom_size, len(df)))\n",
    "            except:\n",
    "                print(\"Invalid input, using default size (300)\")\n",
    "                test_size = 300\n",
    "        else:\n",
    "            print(\"Invalid choice, using default size (300)\")\n",
    "            test_size = 300\n",
    "        \n",
    "        # 限制测试样本最大数量为数据集大小\n",
    "        test_size = min(test_size, len(df))\n",
    "        \n",
    "        # 分层抽样: 确保不同评分等级的样本都被包含\n",
    "        print(\"\\nSelect sampling method:\")\n",
    "        print(\"1. Random sampling\")\n",
    "        print(\"2. Stratified sampling by rating\")\n",
    "        \n",
    "        stratify_choice = input(\"Enter your choice (1-2), or press Enter for default (2): \").strip()\n",
    "        \n",
    "        if stratify_choice == '1':\n",
    "            # 随机抽样\n",
    "            test_sample = df.sample(n=test_size, random_state=42)\n",
    "            print(f\"Using random sampling...\")\n",
    "        else:\n",
    "            # 分层抽样\n",
    "            # 创建评分分组\n",
    "            df['rating_group'] = pd.cut(df['rating'], \n",
    "                                        bins=[0, 1.5, 2.5, 3.5, 4.5, 5.1], \n",
    "                                        labels=['1', '2', '3', '4', '5'],\n",
    "                                        include_lowest=True)\n",
    "            \n",
    "            # 计算每个评分组应该的样本数\n",
    "            rating_counts = df['rating_group'].value_counts()\n",
    "            print(\"\\nRating distribution in dataset:\")\n",
    "            for rating, count in rating_counts.items():\n",
    "                print(f\"  Rating {rating}: {count} samples ({count/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            # 从每个评分组抽样\n",
    "            test_sample = pd.DataFrame()\n",
    "            for rating in rating_counts.index:\n",
    "                group_df = df[df['rating_group'] == rating]\n",
    "                # 计算这个评分组应该抽取的样本数量\n",
    "                group_size = min(int(test_size * (rating_counts[rating] / len(df))), len(group_df))\n",
    "                if group_size > 0:\n",
    "                    group_sample = group_df.sample(n=group_size, random_state=42)\n",
    "                    test_sample = pd.concat([test_sample, group_sample])\n",
    "            \n",
    "            print(f\"Using stratified sampling by rating...\")\n",
    "        \n",
    "        print(f\"Selected {len(test_sample)} samples for validation...\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 实现进度显示\n",
    "        from tqdm import tqdm\n",
    "        import time\n",
    "        \n",
    "        predictions = []\n",
    "        actual_ratings = []\n",
    "        errors = []\n",
    "        display_limit = min(20, len(test_sample))  # 显示前20个样本结果\n",
    "        \n",
    "        print(f\"Processing {len(test_sample)} samples (showing first {display_limit} results)...\")\n",
    "        \n",
    "        try:\n",
    "            # 尝试使用tqdm进度条\n",
    "            for idx, (_, row) in enumerate(tqdm(test_sample.iterrows(), total=len(test_sample), desc=\"Predicting\")):\n",
    "                # Prepare product data\n",
    "                product_data = {\n",
    "                    'product_name': row.get('product_name', ''),\n",
    "                    'category': row.get('category', ''),\n",
    "                    'discounted_price': row.get('discounted_price', ''),\n",
    "                    'actual_price': row.get('actual_price', ''),\n",
    "                    'discount_percentage': row.get('discount_percentage', ''),\n",
    "                    'rating_count': row.get('rating_count', ''),\n",
    "                    'about_product': row.get('about_product', '')\n",
    "                }\n",
    "                \n",
    "                # Make prediction\n",
    "                predicted_rating = predictor.predict_rating(product_data)\n",
    "                actual_rating = row['rating']\n",
    "                \n",
    "                if predicted_rating is not None:\n",
    "                    predictions.append(predicted_rating)\n",
    "                    actual_ratings.append(actual_rating)\n",
    "                    error = abs(predicted_rating - actual_rating)\n",
    "                    errors.append(error)\n",
    "                    \n",
    "                    # Display limited prediction results\n",
    "                    if idx < display_limit:\n",
    "                        print(f\"Sample {idx+1:2d}: Actual={actual_rating:.1f} | Predicted={predicted_rating:.1f} | Error={error:.2f} | {row['product_name'][:30]}...\")\n",
    "        except ImportError:\n",
    "            # 如果没有tqdm，使用简单的进度显示\n",
    "            print(\"Processing samples...\")\n",
    "            total = len(test_sample)\n",
    "            for idx, (_, row) in enumerate(test_sample.iterrows()):\n",
    "                if idx % 10 == 0:\n",
    "                    print(f\"Progress: {idx}/{total} ({idx/total*100:.1f}%)\")\n",
    "                \n",
    "                # Prepare product data\n",
    "                product_data = {\n",
    "                    'product_name': row.get('product_name', ''),\n",
    "                    'category': row.get('category', ''),\n",
    "                    'discounted_price': row.get('discounted_price', ''),\n",
    "                    'actual_price': row.get('actual_price', ''),\n",
    "                    'discount_percentage': row.get('discount_percentage', ''),\n",
    "                    'rating_count': row.get('rating_count', ''),\n",
    "                    'about_product': row.get('about_product', '')\n",
    "                }\n",
    "                \n",
    "                # Make prediction\n",
    "                predicted_rating = predictor.predict_rating(product_data)\n",
    "                actual_rating = row['rating']\n",
    "                \n",
    "                if predicted_rating is not None:\n",
    "                    predictions.append(predicted_rating)\n",
    "                    actual_ratings.append(actual_rating)\n",
    "                    error = abs(predicted_rating - actual_rating)\n",
    "                    errors.append(error)\n",
    "                    \n",
    "                    # Display limited prediction results\n",
    "                    if idx < display_limit:\n",
    "                        print(f\"Sample {idx+1:2d}: Actual={actual_rating:.1f} | Predicted={predicted_rating:.1f} | Error={error:.2f} | {row['product_name'][:30]}...\")\n",
    "        \n",
    "        if len(predictions) > 0:\n",
    "            # Calculate performance metrics\n",
    "            predictions = np.array(predictions)\n",
    "            actual_ratings = np.array(actual_ratings)\n",
    "            errors = np.array(errors)\n",
    "            \n",
    "            mae = np.mean(errors)  # Mean Absolute Error\n",
    "            mse = np.mean(errors**2)  # Mean Squared Error\n",
    "            rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "            \n",
    "            # Calculate R² score\n",
    "            ss_res = np.sum((actual_ratings - predictions) ** 2)\n",
    "            ss_tot = np.sum((actual_ratings - np.mean(actual_ratings)) ** 2)\n",
    "            r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            \n",
    "            # Calculate accuracy at different tolerance levels\n",
    "            accuracy_01 = np.mean(errors <= 0.1) * 100\n",
    "            accuracy_02 = np.mean(errors <= 0.2) * 100\n",
    "            accuracy_03 = np.mean(errors <= 0.3) * 100\n",
    "            accuracy_05 = np.mean(errors <= 0.5) * 100\n",
    "            \n",
    "            # 增加错误分析\n",
    "            error_distribution = {\n",
    "                '0.0-0.1': np.sum((errors > 0.0) & (errors <= 0.1)),\n",
    "                '0.1-0.2': np.sum((errors > 0.1) & (errors <= 0.2)),\n",
    "                '0.2-0.3': np.sum((errors > 0.2) & (errors <= 0.3)),\n",
    "                '0.3-0.5': np.sum((errors > 0.3) & (errors <= 0.5)),\n",
    "                '0.5-1.0': np.sum((errors > 0.5) & (errors <= 1.0)),\n",
    "                '>1.0': np.sum(errors > 1.0)\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nModel Performance Evaluation Results:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Basic Metrics:\")\n",
    "            print(f\"   Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "            print(f\"   Root Mean Square Error (RMSE): {rmse:.3f}\")\n",
    "            print(f\"   R² Score: {r2:.3f}\")\n",
    "            print(f\"   Test Sample Size: {len(predictions)}\")\n",
    "            \n",
    "            print(f\"\\nPrediction Accuracy:\")\n",
    "            print(f\"   Accuracy within ±0.1 points: {accuracy_01:.1f}%\")\n",
    "            print(f\"   Accuracy within ±0.2 points: {accuracy_02:.1f}%\")\n",
    "            print(f\"   Accuracy within ±0.3 points: {accuracy_03:.1f}%\")\n",
    "            print(f\"   Accuracy within ±0.5 points: {accuracy_05:.1f}%\")\n",
    "            \n",
    "            print(f\"\\nError Distribution:\")\n",
    "            total_samples = len(predictions)\n",
    "            for error_range, count in error_distribution.items():\n",
    "                print(f\"   Error {error_range}: {count} samples ({count/total_samples*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nPrediction Distribution:\")\n",
    "            print(f\"   Actual rating range: {actual_ratings.min():.1f} - {actual_ratings.max():.1f}\")\n",
    "            print(f\"   Predicted rating range: {predictions.min():.1f} - {predictions.max():.1f}\")\n",
    "            print(f\"   Average error: {mae:.3f} points\")\n",
    "            print(f\"   Maximum error: {errors.max():.3f} points\")\n",
    "            print(f\"   Minimum error: {errors.min():.3f} points\")\n",
    "            \n",
    "            # 增加按评分分组的错误分析\n",
    "            print(f\"\\nError Analysis by Rating:\")\n",
    "            # 创建评分组\n",
    "            rating_groups = [1, 2, 3, 4, 5]\n",
    "            for rating in rating_groups:\n",
    "                # 获取特定评分的索引\n",
    "                rating_indices = np.where((actual_ratings >= rating-0.5) & (actual_ratings < rating+0.5))[0]\n",
    "                if len(rating_indices) > 0:\n",
    "                    group_errors = errors[rating_indices]\n",
    "                    group_mae = np.mean(group_errors)\n",
    "                    group_accuracy = np.mean(group_errors <= 0.5) * 100\n",
    "                    print(f\"   Rating {rating}: MAE={group_mae:.3f}, Accuracy(±0.5)={group_accuracy:.1f}%, Samples={len(rating_indices)}\")\n",
    "            \n",
    "            # Performance level assessment\n",
    "            print(f\"\\nModel Performance Level:\")\n",
    "            if mae < 0.3:\n",
    "                print(\"   Excellent (MAE < 0.3)\")\n",
    "            elif mae < 0.5:\n",
    "                print(\"   Good (0.3 ≤ MAE < 0.5)\")\n",
    "            elif mae < 0.7:\n",
    "                print(\"   Average (0.5 ≤ MAE < 0.7)\")\n",
    "            else:\n",
    "                print(\"   Needs improvement (MAE ≥ 0.7)\")\n",
    "            \n",
    "            # Provide improvement suggestions\n",
    "            print(f\"\\nModel Optimization Suggestions:\")\n",
    "            if r2 < 0.5:\n",
    "                print(\"   • Consider adding more features or using more complex models\")\n",
    "            if mae > 0.5:\n",
    "                print(\"   • Check outlier handling and feature engineering\")\n",
    "            if accuracy_05 < 80:\n",
    "                print(\"   • Consider using ensemble learning or deep learning methods\")\n",
    "            else:\n",
    "                print(\"   • Model performance is good, consider deploying for use\")\n",
    "        \n",
    "        else:\n",
    "            print(\"All predictions failed, please check the model and data\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"Could not find the amazon.csv file, make sure the data file is in the current directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core function\n",
    "\n",
    "Verify the accuracy of the model:\n",
    "\n",
    "The trained model was tested using real datasets (such as amazon.csv) to evaluate the accuracy of its predicted scores.\n",
    "\n",
    "Support flexible test configuration:\n",
    "\n",
    "Users are allowed to select the size of the test sample (such as 100, 300, 500, 1000 or custom) and the sampling method (random sampling or stratified sampling).\n",
    "\n",
    "Stratified sampling：\n",
    "\n",
    "Ensure that the test set contains samples of different rating grades to avoid data bias and improve the reliability of the verification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Interactive prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_prediction():\n",
    "    \"\"\"Interactive prediction functionality\"\"\"\n",
    "    print(\"\\nInteractive Product Rating Prediction\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Please enter product information for rating prediction:\")\n",
    "    \n",
    "    predictor = AmazonRatingPredictor()\n",
    "    \n",
    "    if predictor.model is None:\n",
    "        print(\"Model not loaded, cannot make predictions\")\n",
    "        return\n",
    "    \n",
    "    # Get user input\n",
    "    product_data = {}\n",
    "    product_data['product_name'] = input(\"Product Name: \")\n",
    "    product_data['category'] = input(\"Product Category (e.g., Electronics|Audio): \")\n",
    "    product_data['discounted_price'] = input(\"Discounted Price (e.g., ₹999): \")\n",
    "    product_data['actual_price'] = input(\"Original Price (e.g., ₹1999): \")\n",
    "    product_data['discount_percentage'] = input(\"Discount Percentage (e.g., 50%): \")\n",
    "    product_data['rating_count'] = input(\"Rating Count (e.g., 1000): \")\n",
    "    product_data['about_product'] = input(\"Product Description: \")\n",
    "    \n",
    "    # Make prediction\n",
    "    result = predictor.predict_with_confidence(product_data)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nPrediction Results:\")\n",
    "        print(f\"Predicted Rating: {result['predicted_rating']}/5.0\")\n",
    "        print(f\"Rating Level: {result['rating_level']}\")\n",
    "        print(f\"Model Used: {result['model_type']}\")\n",
    "        print(f\"\\nAnalysis:\")\n",
    "        for key, value in result['analysis'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in result['recommendations']:\n",
    "            print(f\"  • {rec}\")\n",
    "    else:\n",
    "        print(\"Prediction failed, please check input data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User interaction\n",
    "\n",
    "Prompt the user to enter product information (such as name, category, price, description, etc.) through the command line.\n",
    "\n",
    "Supports dynamic input and is suitable for actual deployment scenarios.\n",
    "\n",
    "Prediction and Result Presentation:\n",
    "\n",
    "Call the 'predict_with_confidence' method to return the predicted score, grade, key influencing factors and improvement suggestions.\n",
    "\n",
    "Format the output result to facilitate user understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Main program entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Amazon Product Rating Prediction System\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nPlease select an operation:\")\n",
    "        print(\"1. Run Demo Prediction\")\n",
    "        print(\"2. Validate with Real Data\")\n",
    "        print(\"3. Interactive Prediction\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (1-4): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            demo_prediction()\n",
    "        elif choice == '2':\n",
    "            validate_with_real_data()\n",
    "        elif choice == '3':\n",
    "            interactive_prediction()\n",
    "        elif choice == '4':\n",
    "            print(\"Thank you for using the system!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice, please try again\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
